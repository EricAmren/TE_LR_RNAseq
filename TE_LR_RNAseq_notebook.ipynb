{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPENDENCIES\n",
    "\n",
    "import pysam\n",
    "import pandas as pd\n",
    "import pstats\n",
    "from tqdm import tqdm as tqdm\n",
    "import cProfile\n",
    "import numpy as np\n",
    "\n",
    "# GLOBAL VARS\n",
    "FC30_DMGOTH_MAX_AS_PRIMARY_ONLY_BAMFILE =\"data/dmgoth101_genome_alignments/bam/FC30.against_dmgoth.filtered_max_AS.primary_only.bam\"\n",
    "FC29_DMGOTH_MAX_AS_PRIMARY_ONLY_BAMFILE =\"data/dmgoth101_genome_alignments/bam/FC29.against_dmgoth.filtered_max_AS.primary_only.bam\"\n",
    "GENE_ANNOTATIONS_FILE = \"data/dmgoth101_genome_alignments/annotations/Dm_Goth_10-1.dmel6.23LiftOff.sorted.gff\"\n",
    "# TE_CLASSIFICATION_FILE= \"/data2/eric/TE_LR_RNAseq/TE_hierarchy.tsv\"\n",
    "TE_CLASSIFICATION_FILE_V3= \"data/dmgoth101_genome_alignments/annotations/TE_classification.from_RM_output_v3.csv\"\n",
    "TE_CLASSIFICATION_FILE_V2= \"data/dmgoth101_genome_alignments/annotations/TE_classification.from_RM_output_v2.csv\"\n",
    "# BLAST_TE_ANNOTATIONS_FILE = \"/data2/eric/TE_LR_RNAseq/data/dmgoth101_genome_alignments/annotations/Dm_Goth_10-1_insertions_vsTEdb.gtf\"\n",
    "RM_TE_ANNOTATION_FILE_V3 = \"data/dmgoth101_genome_alignments/annotations/dmgoth101.onecode.v3.gtf\"\n",
    "RM_TE_ANNOTATION_FILE_V2 = \"data/dmgoth101_genome_alignments/annotations/dmgoth101.onecode.v2.gtf\"\n",
    "\n",
    "# INSERTION_TABLE = \"/data2/eric/TE_LR_RNAseq/data/dmgoth101_genome_alignments/insertion_table.tsv\"\n",
    "\n",
    "# GLOBAL PARAMETERS\n",
    "\n",
    "MIN_SUB_COVERAGE = 0.1 # Threshold used to filter the features (gene or TE) mapped by a read = minimal subject coverage (nb of aligned bases / total nb of feature's bases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gene:\n",
    "\tdef __init__(self, chrom, start, end, gene_id):\n",
    "\t\tself.chrom = chrom\n",
    "\t\tself.start = start\n",
    "\t\tself.end = end\n",
    "\t\tself.gene_id = gene_id\n",
    "\t\tself.exons = set()\n",
    "\t\tself.mrna = set()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.end - self.start\n",
    "\n",
    "\tdef __repr__(self):\n",
    "\t\treturn self.gene_id\n",
    "\n",
    "\n",
    "def parse_gene_annotation_line(line):\n",
    "    sline = line.strip().split(\"\\t\")\n",
    "    chrom = sline[0]\n",
    "    start = int(sline[3])\n",
    "    end = int(sline[4])\n",
    "    gene_id = sline[-1].split(\";\")[0].split('\"')[1]\n",
    "    return Gene(chrom, start, end, gene_id)\n",
    "\n",
    "\n",
    "def is_overlapped(start1, end1, start2, end2):\n",
    "    return end1 >= start2 and end2 >= start1\n",
    "\n",
    "\n",
    "def get_gene_dict(gene_annotation):\n",
    "\tgene_dict = {}\n",
    "\twith open(gene_annotation, 'r') as gene_annot:\n",
    "\t\tfor line in gene_annot:\n",
    "\t\t\tsline = line.strip().split('\\t')\n",
    "\t\t\tgene_id = sline[-1].split(\";\")[0].split('\"')[1]\n",
    "\t\t\tif sline[2] == \"gene\":\n",
    "\t\t\t\tchrom = sline[0]\n",
    "\t\t\t\tnew_gene = parse_gene_annotation_line(line)\n",
    "\t\t\t\tif chrom in gene_dict:\n",
    "\t\t\t\t\tgene_dict[chrom][new_gene.gene_id] = new_gene\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tgene_dict[chrom] = {new_gene.gene_id: new_gene}\n",
    "\t\t\telif sline[2] == \"exon\":\n",
    "\t\t\t\tgene_dict[chrom][gene_id].exons.add(\n",
    "\t\t\t\t\t(int(sline[3]), int(sline[4])))\n",
    "\t\t\telif sline[2] == \"mRNA\":\n",
    "\t\t\t\tgene_dict[chrom][gene_id].mrna.add(\n",
    "\t\t\t\t\t(int(sline[3]), int(sline[4])))\n",
    "\treturn gene_dict\n",
    "\n",
    "\n",
    "def read_TE_classification_file(TE_classification_file):\n",
    "\t\"\"\"From a tsv table with 3 columns : Family, Class, Superfamily,\n",
    "\treturn a pandas dataframe.\n",
    "\n",
    "\tArgs:\n",
    "\t\tTE_classification_file (str): path to the TE classification table (tsv format)\n",
    "\t\"\"\"\n",
    "\twith open(TE_classification_file, 'r') as input:\n",
    "\t\tinput.readline()\n",
    "\t\tfamilies = list()\n",
    "\t\tsuperfamilies = list()\n",
    "\t\tsubclasses = list()\n",
    "\t\tfor line in input:\n",
    "\t\t\tif len(line.split(\"\\t\")) == 3:\n",
    "\t\t\t\tline = line.strip()\n",
    "\t\t\t\tfamily, subclass, superfamily = line.split(\"\\t\")\n",
    "\t\t\t\tfamilies.append(family)\n",
    "\t\t\t\tsuperfamilies.append(superfamily)\n",
    "\t\t\t\tsubclasses.append(subclass)\n",
    "\tTE_classification_df = pd.DataFrame(list(zip(subclasses, superfamilies, families)), columns=[\n",
    "\t                                    'Subclass', 'Superfamily', 'Family'])\n",
    "\treturn TE_classification_df\n",
    "\n",
    "\n",
    "class TE_feature:\n",
    "\tdef __init__(self, chrom, start, end, gene_id, insertion_id):\n",
    "\t\tself.chrom = chrom\n",
    "\t\tself.start = start\n",
    "\t\tself.end = end\n",
    "\t\tself.insertion_id = insertion_id\n",
    "\t\tself.count = 0\n",
    "\t\t# self.family = gene_id_to_family_name(gene_id)\n",
    "\t\tself.counted_reads = set()\n",
    "\t\tself.chimeric_reads = set()\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.end - self.start\n",
    "\n",
    "\tdef __repr__(self):\n",
    "\t\treturn self.insertion_id\n",
    "\n",
    "\tdef is_valid(self, bam_chromosomes):\n",
    "\t\treturn len(self) > 150 and self.chrom in bam_chromosomes\n",
    "\n",
    "\n",
    "def build_TE(line):\n",
    "    sline = line.strip().split(\"\\t\")\n",
    "    chrom = sline[0]\n",
    "    start = int(sline[3])\n",
    "    end = int(sline[4])\n",
    "    gene_id = sline[-1].split(\";\")[0].split('\"')[1]\n",
    "    insertion_id = sline[-1].strip().split('transcript_id \"')[-1][:-2]\n",
    "\n",
    "    return TE_feature(chrom, start, end, gene_id, insertion_id)\n",
    "\n",
    "\n",
    "def filter_relevant_TE_feature(bamfile, TE_annotation_file, min_TE_size=150):\n",
    "\t\"\"\"Generate list of TE objects that will next be counted.\n",
    "\tTE are filtered : we discard those which are on chromosome absent from the bamfile\n",
    "\tand those with length (in number of base) below a certain threshold.\n",
    "\n",
    "\tArgs:\n",
    "\t\tbamfile (str): path to the alignment file\n",
    "\t\tTE_annotation_file (str): path the TE annotation file (gtf format)\n",
    "\t\tmin_TE_size(int): minimal number of base for a TE to be considered as valid. Default = 150\n",
    "\t\"\"\"\n",
    "\t# Enumerating chromosomes present in the bamfile\n",
    "\tbam_chromosomes = pysam.AlignmentFile(bamfile).references\n",
    "\t# Then iterating through TE_annotation_file, creating and checking TE objects\n",
    "\tvalid_TE_list = list()\n",
    "\twith open(TE_annotation_file, \"r\") as TE_annot:\n",
    "\t\tfor line in TE_annot:\n",
    "\t\t\tnew_TE = build_TE(line)\n",
    "\t\t\tif new_TE.is_valid(bam_chromosomes):\n",
    "\t\t\t\tvalid_TE_list.append(new_TE)\n",
    "\treturn valid_TE_list\n",
    "\n",
    "\n",
    "def regroup_TE_by_chrom(TE_feature_list):\n",
    "\t\"\"\"Return a dict of key:chrom and values:list of TE\n",
    "\n",
    "\tArgs:\n",
    "\t\tTE_feature_list (list): flat list of TE_feature\n",
    "\t\"\"\"\n",
    "\tTE_dict = dict()\n",
    "\tfor insertion in TE_feature_list:\n",
    "\t\tif insertion.chrom not in TE_dict:\n",
    "\t\t\tTE_dict[insertion.chrom] = [insertion]\n",
    "\t\telse:\n",
    "\t\t\tTE_dict[insertion.chrom].append(insertion)\n",
    "\treturn TE_dict\n",
    "\n",
    "\n",
    "def get_all_reads_covering_TE(TE_by_chrom, bamfile):\n",
    "\t\"\"\"Get a list of all reads that cover a TE.\n",
    "\n",
    "\tArgs:\n",
    "\t\tTE_by_chrom (dict): dict of TE_feature ordered by chromosome\n",
    "\t\tbamfile (str): path to the alignment file\n",
    "\t\"\"\"\n",
    "\treads_mapped_on_TE = set()\n",
    "\twith pysam.AlignmentFile(bamfile) as bam:\n",
    "\t\tfor chrom, TE_list in tqdm(TE_by_chrom.items(), desc=\"Chromosome\", position=0, leave=True):\n",
    "\t\t\tfor TE in tqdm(TE_list, desc=chrom, position=0, leave=True):\n",
    "\t\t\t\treads_fetched = list(bam.fetch( contig=TE.chrom, start=TE.start, stop=TE.end) )\n",
    "\t\t\t\t# Only keeping reads that are at least aligned once in a TE insertion :\n",
    "\t\t\t\toverlapped_reads = [read for read in reads_fetched if read.get_overlap(TE.start, TE.end)]\n",
    "\t\t\t\treads_mapped_on_TE.update(overlapped_reads)\n",
    "\treturn reads_mapped_on_TE\n",
    "\n",
    "\n",
    "# TODO don't forget to fix comments when done\n",
    "def get_overlapped_genes(read, gene_dict):\n",
    "\t\"\"\"Takes a read and a dictionnary of dictionnaries (chrom -> gene_id -> [start, end])\n",
    "\t and returns a list of all overlapped genes.\n",
    "\n",
    "\tArgs:\n",
    "\t\tread (pysam.AlignedSegment): the read we want to map\n",
    "\t\tgene_dict (dict): a dict of dict (gene start/end by gene_id by chrom)\n",
    "\n",
    "\tReturns:\n",
    "\t\toverlapped_genes_dict (dict) : dict of all genes covered by the read with their start and end position as values\n",
    "\n",
    "\t\"\"\"\n",
    "\toverlapped_genes = list()\n",
    "\tchrom = read.reference_name\n",
    "\tgene_list = gene_dict[chrom].values()\n",
    "\toverlapped_genes = [gene for gene in gene_list if is_overlapped(\n",
    "\t    read.reference_start, read.reference_end, gene.start, gene.end)]\n",
    "\treturn overlapped_genes\n",
    "\n",
    "\t# overlapped_genes = list()\n",
    "\t# chrom = read.reference_name\n",
    "\t# overlapped_genes = gene_df[(gene_df.feature == \"gene\") & (gene_df.seqname == chrom) & (read.reference_end >= gene_df.start) & (gene_df.end >= read.reference_start)]\n",
    "\t# genes_positions = [(start, end) for start, end in zip(list(overlapped_genes.start), list(overlapped_genes.end))]\n",
    "\t# overlapped_genes_dict = dict(zip(list(overlapped_genes.gene_id), genes_positions))\n",
    "\t# return overlapped_genes_dict\n",
    "\n",
    "\n",
    "def get_overlapped_TE(read, TE_by_chrom):\n",
    "\t\"\"\"Get all TE feature that are covered by a read\n",
    "\n",
    "\tArgs:\n",
    "\t\tread (pysam.AlignedSegment): the read we want to map\n",
    "\t\tTE_by_chrom (dict): dict of TE_feature with key:chrom, value:list of TE\n",
    "\t\"\"\"\n",
    "\tlist_of_overlapped_TE = list()\n",
    "\tchrom = read.reference_name\n",
    "\tfor insertion in TE_by_chrom[chrom]:\n",
    "\t\tif read.get_overlap(insertion.start, insertion.end):  # if at least 1 base aligned in TE\n",
    "\t\t\tlist_of_overlapped_TE.append(insertion)\n",
    "\treturn list_of_overlapped_TE\n",
    "\n",
    "\n",
    "def get_subject_coverage(alignment, insertion):\n",
    "\tinsertion_length = insertion.end - insertion.start\n",
    "\toverlap_start = max(alignment.reference_start, insertion.start)\n",
    "\toverlap_end = min(alignment.reference_end, insertion.end)\n",
    "\toverlap_length = overlap_end - overlap_start\n",
    "\tinsertion_length = insertion.end - insertion.start\n",
    "\tif insertion_length != 0:\n",
    "\t\tsubject_coverage = overlap_length / insertion_length\n",
    "\telse:\n",
    "\t\tsubject_coverage = 0\n",
    "\treturn subject_coverage\n",
    "\n",
    "def get_nb_of_non_overlapping_bases(x_start, x_end, y_start, y_end):\n",
    "\tstart_overlap = abs(x_start - y_start)\n",
    "\tend_overlap = abs(x_end - y_end)\n",
    "\treturn start_overlap + end_overlap\n",
    "\n",
    "\n",
    "def choose_feature_with_less_non_overlapping_bases(read, list_of_TE, list_of_gene):\n",
    "\t# Return TE if TE is the best feature, else 0\n",
    "\tmin_nob = 999999999999\n",
    "\toptimal_feature = None\n",
    "\tfor TE in list_of_TE:\n",
    "\t\tnb_of_nob = get_nb_of_non_overlapping_bases(TE.start, TE.end, read.reference_start, read.reference_end)\n",
    "\t\tif nb_of_nob < min_nob:\n",
    "\t\t\tmin_nob = nb_of_nob\n",
    "\t\t\toptimal_feature = TE\n",
    "\tfor gene in list_of_gene:\n",
    "\t\tfor mrna_start, mrna_end in gene.mrna:\n",
    "\t\t\tnb_of_nob = get_nb_of_non_overlapping_bases(mrna_start, mrna_end, read.reference_start, read.reference_end)\n",
    "\t\t\tif nb_of_nob < min_nob:\n",
    "\t\t\t\treturn 0\n",
    "\t\tnb_of_nob = get_nb_of_non_overlapping_bases(gene.start, gene.end, read.reference_start, read.reference_end)\n",
    "\t\tif nb_of_nob < min_nob:\n",
    "\t\t\treturn 0\n",
    "\treturn optimal_feature\n",
    "\n",
    "\n",
    "def get_gene_exonic_positions(gene_id, gene_df):\n",
    "\t\"\"\"Used to get exonic positions of a gene\n",
    "\n",
    "\tArgs:\n",
    "\t\tgene_id (str): the id of the gene we want to look at\n",
    "\t\tgene_df (pandas.DataFrame): a df describing the gene annotation (gtf)\n",
    "\n",
    "\tReturns:\n",
    "\t\tList of Tuples: List of tuples with start and end positions of each exons of the gene\n",
    "\t\"\"\"\n",
    "\texons=gene_df[(gene_df.gene_id == gene_id) and (gene_df.feature == \"exon\")]\n",
    "\texonic_positions=[(start, end)\n",
    "\t                   for start, end in zip(list(exons.start), list(exons.end))]\n",
    "\treturn exonic_positions\n",
    "\n",
    "def check_if_exonic_alignment(read, gene):  # TODO : clean comments\n",
    "\t\"\"\"Return True if a read has at least 1 base aligned with an exon of a gene.\n",
    "\n",
    "\tArgs:\n",
    "\t\tread (pysam.AlignedSegment): a pysam read\n",
    "\t\tgene (Gene):\n",
    "\n",
    "\tReturns:\n",
    "\t\tbool: True if aligned in exonic region, else false\n",
    "\t\"\"\"\n",
    "\texonic_positions=sorted(list(gene.exons))\n",
    "\tfor exonStart, exonEnd in exonic_positions:\n",
    "\t\tif read.reference_end >= exonStart and exonEnd >= read.reference_start:\n",
    "\t\t\treturn True\n",
    "\treturn False\n",
    "\n",
    "\t# gene = gene_df[gene_df.gene_id == gene_id]\n",
    "\t# if str(gene.seqname) != read.reference_name or read.reference_end < gene.start:\n",
    "\t# \treturn False\n",
    "\t# if read.reference_end >= gene.start and gene.end >= read.reference_start :\n",
    "\t# \texonic_positions = get_gene_exonic_positions(gene_id, gene_df)\n",
    "\t# \tfor exonStart, exonEnd in exonic_positions :\n",
    "\t# \t\tif read.get_overlap(exonStart, exonEnd):\n",
    "\t# \t\t\treturn True\n",
    "\t# return False\n",
    "\n",
    "def default_filter(alignment, insertion, subcov_threshold):\n",
    "    subject_coverage=get_subject_coverage(alignment, insertion)\n",
    "    nb_aligned_pairs=alignment.get_overlap(insertion.start, insertion.end)\n",
    "    is_ok=(subject_coverage > subcov_threshold and nb_aligned_pairs > 1)\n",
    "    return is_ok\n",
    "\n",
    "def increment_TE_count(TE_by_chrom, reads_list, gene_dict, subcov_threshold=MIN_SUB_COVERAGE):  # TODO : fix Args !\n",
    "\t\"\"\"Iterate through each read that covers a TE and decide if we increment (or not)\n",
    "\tits read counter. This decision depends on several conditions described in the filter function.\n",
    "\tReturn an update dict of TE, with counting + several other counters\n",
    "\t\t(1) : total_nb_of_reads covering a TE\n",
    "\t\t(2) : nb_of_chimeric_reads : count the nb of chimeric read (non-linear alignment)\n",
    "\t\t(3) : the read must not be better aligned to another feature\n",
    "\t\t(4) : TODO : CO-EXPRESSED ?\n",
    "\n",
    "\tArgs:\n",
    "\t\tTE_by_chrom (dict): dict of TE_feature with key:chrom, value:list of TE\n",
    "\t\treads_list (list): list of all the reads that cover a TE locus\n",
    "\t\tgene_annotation (dict): dict of Gene_feature with key:chrom, value:list of TE\n",
    "\t\"\"\"\n",
    "\tnot_covered_by_min_subcov = 0\n",
    "\tbest_aligned_on_gene = 0\n",
    "\texonic = 0\n",
    "\tintronic = 0\n",
    "\tmultiple_TE = 0\n",
    "\tnon_ambiguous = 0\n",
    "\ttotal_read = len(reads_list)\n",
    "\twith open('chimeric_that_pass_all_filters.v2.female.tsv', 'w') as output:\n",
    "\t\tfor read in tqdm(reads_list, position=0, leave=True):\n",
    "\t\t\t# (1) Fetching TE insertions that are at least covered by one base.\n",
    "\t\t\toverlapped_TE=get_overlapped_TE(read, TE_by_chrom)\n",
    "\n",
    "\t\t\t# (2) filtering TE that are not covered by at least 10% of their length and at least 1 aligned base\n",
    "\t\t\toverlapped_TE=[TE for TE in overlapped_TE if default_filter(read, TE, subcov_threshold)]\n",
    "\t\t\tif not overlapped_TE :\n",
    "\t\t\t\tnot_covered_by_min_subcov += 1\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t# (3) filtering feature with the less non-overlapping bases\n",
    "\t\t\toverlapped_genes=get_overlapped_genes(read, gene_dict)\n",
    "\t\t\toverlapped_in_gene_exons=[gene for gene in overlapped_genes if check_if_exonic_alignment(read, gene)]\n",
    "\n",
    "\t\t\tchosen_feature=choose_feature_with_less_non_overlapping_bases(read, overlapped_TE, overlapped_in_gene_exons)\n",
    "\t\t\tif isinstance(chosen_feature, TE_feature):\n",
    "\t\t\t\tchosen_feature.count += 1\n",
    "\t\t\t\tchosen_feature.counted_reads.add(read)\n",
    "\t\t\t\tif overlapped_genes :\n",
    "\t\t\t\t\tif overlapped_in_gene_exons :\n",
    "\t\t\t\t\t\texonic += 1\n",
    "\t\t\t\t\t\t# new_line = \"\\t\".join([chosen_feature.insertion_id, read.query_name, read.reference_name, str(read.reference_start), str(read.reference_end)]) + \"\\n\"\n",
    "\t\t\t\t\t\tchimeric = True\n",
    "\t\t\t\t\t\tfor gene in overlapped_genes :\n",
    "\t\t\t\t\t\t\tfor exon in gene.exons:\n",
    "\t\t\t\t\t\t\t\tif is_overlapped(exon[0], exon[1], chosen_feature.start, chosen_feature.end):\n",
    "\t\t\t\t\t\t\t\t\tchimeric = False\n",
    "\t\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\tif chimeric :\n",
    "\t\t\t\t\t\t\tnew_line = \"\\t\".join([chosen_feature.insertion_id, read.query_name, read.reference_name, str(read.reference_start), str(read.reference_end)]) + \"\\n\"\n",
    "\t\t\t\t\t\t\toutput.write(new_line)\n",
    "\t\t\t\t\telse :\n",
    "\t\t\t\t\t\tintronic += 1\n",
    "\t\t\t\telse :\n",
    "\t\t\t\t\tif len(overlapped_TE) > 1:\n",
    "\t\t\t\t\t\tmultiple_TE += 1\n",
    "\t\t\t\t\telse :\n",
    "\t\t\t\t\t\tnon_ambiguous += 1\n",
    "\t\t\telse :\n",
    "\t\t\t\tbest_aligned_on_gene += 1\n",
    "\tcounters = [total_read, non_ambiguous, multiple_TE, exonic, intronic, not_covered_by_min_subcov, best_aligned_on_gene]\n",
    "\treturn counters\n",
    "\n",
    "\n",
    "\n",
    "def generate_counting(bamfile, TE_annotation_file, gene_annotation_file):\n",
    "\t\"\"\"Measure the expression of each TE by number of mapped reads.\n",
    "\tReturn a dict with key = insertion_name and value = a list of mapped read\n",
    "\n",
    "\tArgs:\n",
    "\t\tbamfile (str): path to the alignment file\n",
    "\t\tTE_annotation_file (str): path to the TE annotation file in gtf format\n",
    "\t\tgene_annotation_file (str): path to the gene annotation file in gtf format\n",
    "\t\tTE_classification_file (str): path to a tsv table with TE classification (family superfamily, subclass)\n",
    "\t\"\"\"\n",
    "\tprint(\"Filtering valid TE...\")\n",
    "\tgene_dict=get_gene_dict(gene_annotation_file)\n",
    "\tfiltered_TE_features=filter_relevant_TE_feature(bamfile, TE_annotation_file)\n",
    "\tTE_by_chrom=regroup_TE_by_chrom(filtered_TE_features)\n",
    "\tprint(\"Recovering reads covering TE...\")\n",
    "\treads_covering_TE=get_all_reads_covering_TE(TE_by_chrom, bamfile)\n",
    "\tprint(\"Done\")\n",
    "\tprint(\"Incrementing TE counts...\")\n",
    "\tcounters_results=increment_TE_count(TE_by_chrom, reads_covering_TE,  gene_dict)\n",
    "\tprint(\"Done\")\n",
    "\treturn [TE_by_chrom, counters_results]\n",
    "\n",
    "def from_raw_counting_to_df(TE_dict, TE_classification_file):\n",
    "\t\"\"\"Convert dict of counting generated by func \"generate_counting\" into a more user-friendly dataframe.\n",
    "\n",
    "\tArgs:\n",
    "\t\tTE_dict (dict): dictionnary of every TE insertion by chromosome with counting and all...\n",
    "\t\tTE_classification_file (str): path to a tsv table with TE classification (family superfamily, subclass)\n",
    "\n",
    "\tReturns:\n",
    "\t\tpd.DataFrame: a pandas dataframe containing informations about each TE insertions (ID, counting, reads counted...)\n",
    "\t\"\"\"\n",
    "\tTE_classification_df=pd.read_csv(TE_classification_file, sep=\"\\t\", names=[\n",
    "\t                                 \"Subclass\", \"Superfamily\", \"Family\", \"Insertion\"])\n",
    "\tflat_insertion_list=[]\n",
    "\tfor insertion_list in TE_dict.values():\n",
    "\t\tflat_insertion_list += insertion_list\n",
    "\tinsertion_dict=dict(zip([insertion.insertion_id for insertion in flat_insertion_list], [\n",
    "\t                    insertion for insertion in flat_insertion_list]))\n",
    "\tcounting_list=[insertion.count for insertion in flat_insertion_list]\n",
    "\tcounted_read_list=[\n",
    "\t    insertion.counted_reads for insertion in flat_insertion_list]\n",
    "\tcounting_df=pd.DataFrame(list(zip(insertion_dict.keys(), counting_list, counted_read_list)),\n",
    "\t\t\t\tcolumns=['Insertion', 'Counting', 'Reads'])\n",
    "\tcounting_df=TE_classification_df.merge(counting_df, on=\"Insertion\")\n",
    "\tadd_mean_subject_coverage_to_df(counting_df, insertion_dict)\n",
    "\treturn counting_df\n",
    "\n",
    "def get_insertion_mean_subject_coverage(insertion_id, counted_reads, insertion_dict):\n",
    "\n",
    "    insertion=insertion_dict[insertion_id]\n",
    "    mean_subject_coverage=0\n",
    "    for read in counted_reads:\n",
    "        mean_subject_coverage += get_subject_coverage(read, insertion)\n",
    "    if len(counted_reads) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return mean_subject_coverage/len(counted_reads)\n",
    "\n",
    "def add_mean_subject_coverage_to_df(counting_df, insertion_dict):\n",
    "    counting_df[\"mean_subcov\"]=counting_df.apply(lambda x: get_insertion_mean_subject_coverage(\n",
    "        x['Insertion'], x['Reads'], insertion_dict), axis=1)\n",
    "    return counting_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering valid TE...\n",
      "Recovering reads covering TE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2L_RaGOO: 100%|██████████| 1240/1240 [00:12<00:00, 97.11it/s] \n",
      "2R_RaGOO: 100%|██████████| 3149/3149 [00:11<00:00, 272.09it/s]\n",
      "3L_RaGOO: 100%|██████████| 2658/2658 [00:07<00:00, 372.17it/s]\n",
      "3R_RaGOO: 100%|██████████| 2127/2127 [00:04<00:00, 458.74it/s]\n",
      "4_RaGOO: 100%|██████████| 461/461 [00:02<00:00, 173.18it/s]\n",
      "X_RaGOO: 100%|██████████| 1030/1030 [00:03<00:00, 267.94it/s]\n",
      "Chromosome: 100%|██████████| 6/6 [00:42<00:00,  7.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Incrementing TE counts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7332/7332 [03:46<00:00, 32.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "[7332, 489, 101, 452, 280, 1386, 4624]\n"
     ]
    }
   ],
   "source": [
    "def generate_TE_df(bamfile, TE_gtf, gene_gtf, TE_classification_file):\n",
    "\t# with cProfile.Profile() as pr:\n",
    "\tTE_by_chrom, counters_results = generate_counting(bamfile, TE_gtf, gene_gtf)\n",
    "\tprint(counters_results)\n",
    "\tbig_TE_df = from_raw_counting_to_df(TE_by_chrom, TE_classification_file)\n",
    "\treturn [big_TE_df, counters_results]\n",
    "\n",
    "# FC29_TE_df, FC29_counters = generate_TE_df(FC29_DMGOTH_MAX_AS_PRIMARY_ONLY_BAMFILE, RM_TE_ANNOTATION_FILE_V3, GENE_ANNOTATIONS_FILE, TE_CLASSIFICATION_FILE_V3)\n",
    "FC30_TE_df, FC30_counters = generate_TE_df(FC30_DMGOTH_MAX_AS_PRIMARY_ONLY_BAMFILE, RM_TE_ANNOTATION_FILE_V3, GENE_ANNOTATIONS_FILE, TE_CLASSIFICATION_FILE_V3)\n",
    "\n",
    "# FC29_TE_df, FC29_counters = generate_TE_df(FC29_DMGOTH_MAX_AS_PRIMARY_ONLY_BAMFILE, RM_TE_ANNOTATION_FILE_V2, GENE_ANNOTATIONS_FILE, TE_CLASSIFICATION_FILE_V2)\n",
    "# FC30_TE_df, FC30_counters = generate_TE_df(FC30_DMGOTH_MAX_AS_PRIMARY_ONLY_BAMFILE, RM_TE_ANNOTATION_FILE_V2, GENE_ANNOTATIONS_FILE, TE_CLASSIFICATION_FILE_V2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FC29_TE_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-43a63dfd653e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcounting_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msave_counting_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFC29_TE_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/data2/eric/TE_LR_RNAseq/countings/FC29_counting_df.v3.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msave_counting_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFC30_TE_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/data2/eric/TE_LR_RNAseq/countings/FC30_counting_df.v3.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FC29_TE_df' is not defined"
     ]
    }
   ],
   "source": [
    "def save_counting_df(counting_df, csv_file):\n",
    "    counting_df.to_csv(csv_file, sep = '\\t', index=False)\n",
    "\n",
    "save_counting_df(FC29_TE_df, \"/data2/eric/TE_LR_RNAseq/countings/FC29_counting_df.v3.tsv\")\n",
    "save_counting_df(FC30_TE_df, \"/data2/eric/TE_LR_RNAseq/countings/FC30_counting_df.v3.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_counting_df(counting_df, csv_file):\n",
    "#     counting_df.to_csv(csv_file, sep = '\\t', index=False)\n",
    "\n",
    "# # save_counting_df(FC29_counting_df, \"FC29_counting_df.v2.tsv\")\n",
    "# # save_counting_df(FC30_counting_df, \"FC30_counting_df.v2.tsv\")\n",
    "\n",
    "# ### SAVING COUNTING_DF WITH CHIMERIC READS EXCLUDED\n",
    "# # save_counting_df(FC29_counting_df, \"FC29_counting_df.v2.chimeric_reads_excluded.tsv\")\n",
    "# # save_counting_df(FC30_counting_df, \"FC30_counting_df.v2.chimeric_reads_excluded.tsv\")\n",
    "\n",
    "# ### SAVING COUNTING_DF co_expressed\n",
    "# save_counting_df(FC29_TE_df, \"/data2/eric/TE_LR_RNAseq/countings/FC29_counting_df.v3.tsv\")\n",
    "# save_counting_df(FC30_TE_df, \"/data2/eric/TE_LR_RNAseq/countings/FC30_counting_df.v3.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = expression_df.copy()\n",
    "# df = df[df[\"Counting\"] > 2]\n",
    "# df[\"exp_diff\"] = df[\"Expression\"] - df[\"Expression_no_chimere\"]\n",
    "# fig = px.scatter(df, y=\"exp_diff\", x=\"Insertion\", color=\"Family\", size=\"Insertion_length\")\n",
    "# # fig.update_traces(marker_size=10)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# df = expression_df.copy()\n",
    "# df = df[df[\"Counting\"] > 2]\n",
    "# df[\"count_diff\"] = df[\"Counting\"] - df[\"Counting_no_chimere\"]\n",
    "# fig = px.scatter(df, y=\"count_diff\", x=\"Insertion\", color=\"Family\", size=\"Insertion_length\")\n",
    "# # fig.update_traces(marker_size=10)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT COUNTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 100)\n",
    "# saved_FC29_counting_df_v3.sort_values(by=['Counting'], ascending=False).head(100)\n",
    "# print(saved_FC29_counting_df_v3[saved_FC29_counting_df_v3['Family'] == \"Copia_LTR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insertion_length(insertion_name):\n",
    "\tstart, end = insertion_name.split('$')[-2:]\n",
    "\treturn int(end) - int(start) + 1\n",
    "\n",
    "def get_insertion_merged_df(female_counting, male_counting):\n",
    "\tinsertion_list = set(list(female_counting[\"Insertion\"]) + list(male_counting[\"Insertion\"]))\n",
    "\tsubclass_list = []\n",
    "\tsuperfamily_list = []\n",
    "\tfamily_list = []\n",
    "\tmale_counting_list = []\n",
    "\tfemale_counting_list = []\n",
    "\tinsertion_length_list = []\n",
    "\tfor insertion in insertion_list :\n",
    "\t\tif insertion in list(female_counting[\"Insertion\"]) and insertion in list(male_counting[\"Insertion\"]):\n",
    "\t\t\tinsertion_df = female_counting[female_counting[\"Insertion\"] == insertion]\n",
    "\t\t\tfemale_counting_list.append(insertion_df[\"Counting\"].values[0])\n",
    "\t\t\tmale_counting_list.append(male_counting[male_counting[\"Insertion\"] == insertion][\"Counting\"].values[0])\n",
    "\t\t\t\n",
    "\t\telif insertion in list(female_counting[\"Insertion\"]) :\n",
    "\t\t\tinsertion_df = female_counting[female_counting[\"Insertion\"] == insertion]\n",
    "\t\t\tfemale_counting_list.append(insertion_df[\"Counting\"].values[0])\n",
    "\t\t\tmale_counting_list.append(0)\n",
    "\t\telse :\n",
    "\t\t\tinsertion_df = male_counting[male_counting[\"Insertion\"] == insertion]\n",
    "\t\t\tmale_counting_list.append(insertion_df[\"Counting\"].values[0])\n",
    "\t\t\tfemale_counting_list.append(0)\n",
    "\t\tsubclass_list.append(insertion_df[\"Subclass\"].values[0])\n",
    "\t\tsuperfamily_list.append(insertion_df[\"Superfamily\"].values[0])\n",
    "\t\tfamily_list.append(insertion_df[\"Family\"].values[0])\n",
    "\t\tinsertion_length_list.append(get_insertion_length(insertion))\n",
    "\n",
    "\tinsertion_merged_df = pd.DataFrame(list(zip(subclass_list, superfamily_list, family_list, insertion_list, insertion_length_list, female_counting_list, male_counting_list )), columns=[\"Subclass\", \"Superfamily\", \"Family\", \"Insertion\", \"Length\", \"Female_counting\", \"Male_counting\"])\n",
    "\n",
    "\treturn insertion_merged_df\n",
    "\n",
    "insertion_merged_df = get_insertion_merged_df(saved_FC30_counting_df_v3, saved_FC29_counting_df_v3)\n",
    "# print(insertion_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subclass</th>\n",
       "      <th>Superfamily</th>\n",
       "      <th>Family</th>\n",
       "      <th>Insertion</th>\n",
       "      <th>Length</th>\n",
       "      <th>Female_counting</th>\n",
       "      <th>Male_counting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINE</td>\n",
       "      <td>I-Jockey</td>\n",
       "      <td>G4_DM</td>\n",
       "      <td>G4_DM$3R_RaGOO$2542636$2543942</td>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Gypsy</td>\n",
       "      <td>Gypsy9_I</td>\n",
       "      <td>Gypsy9_I$2R_RaGOO$129419$129869</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LINE</td>\n",
       "      <td>I-Jockey</td>\n",
       "      <td>DOC5_DM</td>\n",
       "      <td>DOC5_DM$2R_RaGOO$1199863$1200279</td>\n",
       "      <td>417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Gypsy</td>\n",
       "      <td>Gypsy2-I_DM</td>\n",
       "      <td>Gypsy2-I_DM$2R_RaGOO$32165$32623</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LINE</td>\n",
       "      <td>I-Jockey</td>\n",
       "      <td>DOC5_DM</td>\n",
       "      <td>DOC5_DM$2R_RaGOO$373938$374143</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Gypsy</td>\n",
       "      <td>DMLTR5</td>\n",
       "      <td>DMLTR5$3L_RaGOO$26377510$26377809</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10661</th>\n",
       "      <td>DNA</td>\n",
       "      <td>P</td>\n",
       "      <td>PROTOP_A</td>\n",
       "      <td>PROTOP_A$3L_RaGOO$24240644$24240874</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10662</th>\n",
       "      <td>DNA</td>\n",
       "      <td>TcMar-Tc1</td>\n",
       "      <td>TC1_DM</td>\n",
       "      <td>TC1_DM$3L_RaGOO$21112446$21113000</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10663</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Gypsy</td>\n",
       "      <td>HMSBEAGLE_I</td>\n",
       "      <td>HMSBEAGLE_I$3L_RaGOO$24883991$24885452</td>\n",
       "      <td>1462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Gypsy</td>\n",
       "      <td>CIRCE</td>\n",
       "      <td>CIRCE$2L_RaGOO$21118081$21120425</td>\n",
       "      <td>2345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10665 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subclass Superfamily       Family  \\\n",
       "0         LINE    I-Jockey        G4_DM   \n",
       "1          LTR       Gypsy     Gypsy9_I   \n",
       "2         LINE    I-Jockey      DOC5_DM   \n",
       "3          LTR       Gypsy  Gypsy2-I_DM   \n",
       "4         LINE    I-Jockey      DOC5_DM   \n",
       "...        ...         ...          ...   \n",
       "10660      LTR       Gypsy       DMLTR5   \n",
       "10661      DNA           P     PROTOP_A   \n",
       "10662      DNA   TcMar-Tc1       TC1_DM   \n",
       "10663      LTR       Gypsy  HMSBEAGLE_I   \n",
       "10664      LTR       Gypsy        CIRCE   \n",
       "\n",
       "                                    Insertion  Length  Female_counting  \\\n",
       "0              G4_DM$3R_RaGOO$2542636$2543942    1307                0   \n",
       "1             Gypsy9_I$2R_RaGOO$129419$129869     451                0   \n",
       "2            DOC5_DM$2R_RaGOO$1199863$1200279     417                0   \n",
       "3            Gypsy2-I_DM$2R_RaGOO$32165$32623     459                0   \n",
       "4              DOC5_DM$2R_RaGOO$373938$374143     206                0   \n",
       "...                                       ...     ...              ...   \n",
       "10660       DMLTR5$3L_RaGOO$26377510$26377809     300                0   \n",
       "10661     PROTOP_A$3L_RaGOO$24240644$24240874     231                0   \n",
       "10662       TC1_DM$3L_RaGOO$21112446$21113000     555                0   \n",
       "10663  HMSBEAGLE_I$3L_RaGOO$24883991$24885452    1462                0   \n",
       "10664        CIRCE$2L_RaGOO$21118081$21120425    2345                0   \n",
       "\n",
       "       Male_counting  \n",
       "0                  2  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "10660              0  \n",
       "10661              0  \n",
       "10662              1  \n",
       "10663              0  \n",
       "10664              0  \n",
       "\n",
       "[10665 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insertion_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merging the female and male dataframe by family and adding more info like nb of expressed insertion and insertion length...\n",
    "\n",
    "def get_insertion_length(insertion_name):\n",
    "\tstart, end = insertion_name.split('$')[-2:]\n",
    "\treturn int(end) - int(start) + 1\n",
    "\n",
    "def create_summary_table(counting_table):\n",
    "\tsubclass_list = []\n",
    "\tsuperfamily_list = []\n",
    "\tfamily_list = counting_table[\"Family\"].unique()\n",
    "\tmin_TE_length_list = []\n",
    "\tmax_TE_length_list = []\n",
    "\tcounting_list = []\n",
    "\tnb_expressed_insertion_list = []\n",
    "\tnb_insertion_list = []\n",
    "\tmost_expressed_insertion_list = []\n",
    "\tfor family in family_list :\n",
    "\t\tfamily_df = counting_table[counting_table[\"Family\"] == family]\n",
    "\t\tsubclass_list.append(family_df[\"Subclass\"].values[0])\n",
    "\t\tsuperfamily_list.append(family_df[\"Superfamily\"].values[0])\n",
    "\t\tmin_TE_length = 9999999\n",
    "\t\tmax_TE_length = 0\n",
    "\t\tfor insertion_name in family_df[\"Insertion\"]:\n",
    "\t\t\tinsertion_length = get_insertion_length(insertion_name)\n",
    "\t\t\tif insertion_length < min_TE_length :\n",
    "\t\t\t\tmin_TE_length = insertion_length\n",
    "\t\t\tif insertion_length > max_TE_length :\n",
    "\t\t\t\tmax_TE_length = insertion_length\n",
    "\t\tmin_TE_length_list.append(min_TE_length)\n",
    "\t\tmax_TE_length_list.append(max_TE_length)\n",
    "\t\tnb_insertion_list.append(len(family_df[\"Insertion\"]))\n",
    "\t\tcounting_list.append(family_df[\"Counting\"].sum())\n",
    "\t\tnb_expressed_insertion_list.append(len(family_df[family_df[\"Counting\"] > 0]))\n",
    "\t\tmost_expressed_insertion_list.append(family_df[family_df[\"Counting\"] == family_df[\"Counting\"].max()][\"Insertion\"].values[0])\n",
    "    \n",
    "\tsummary_df = pd.DataFrame(list(zip(subclass_list, superfamily_list, family_list, min_TE_length_list, max_TE_length_list, counting_list, nb_insertion_list, nb_expressed_insertion_list, most_expressed_insertion_list)), columns=[\"Subclass\", \"Superfamily\", \"Family\", \"Min_TE_length\",\"Max_TE_length\", \"Counts\", \"nb_of_insertion\", \"nb_of_expressed_insertion\", \"Most_expressed_insertion\"])\n",
    "\treturn summary_df\n",
    "\n",
    "\n",
    "def merge_female_and_male_df(female_counting, male_counting):\n",
    "\tfemale_df = create_summary_table(female_counting)\n",
    "\tmale_df = create_summary_table(male_counting)\n",
    "\thierarchy_cols = female_df[[\"Subclass\", \"Superfamily\", \"Family\", \"nb_of_insertion\", \"Min_TE_length\",\"Max_TE_length\"]]\n",
    "\thierarchy_df = hierarchy_cols.copy()\n",
    "\tfull_summary_df = hierarchy_df.merge(female_df.drop(columns=[\"Subclass\", \"Superfamily\", \"Min_TE_length\",\"Max_TE_length\", \"nb_of_insertion\"]), on='Family').merge(male_df.drop(columns=[\"Subclass\", \"Superfamily\", \"Min_TE_length\",\"Max_TE_length\", \"nb_of_insertion\"]), on='Family')\n",
    "\tfull_summary_df.columns = [\"Subclass\", \"Superfamily\", \"Family\", \"nb_of_insertion\", \"Min_TE_length\", \"Max_TE_length\", \"Female_Counts\", \"Female_nb_of_expressed_insertion\", \"Female_most_expressed_insertion\", \"Male_Counts\", \"Male_nb_of_expressed_insertion\", \"Male_most_expressed_insertion\"]\n",
    "\n",
    "\treturn full_summary_df\n",
    "\n",
    "merged_full_summary_df = merge_female_and_male_df(saved_FC30_counting_df_v3, saved_FC29_counting_df_v3)\n",
    "# print(merged_full_summary_df)\n",
    "# save_counting_df(merged_full_summary_df, \"merged_full_summary.v2.tsv\")\n",
    "\n",
    "# def create_table_from_counting(female_counting, male_counting, hierarchy):\n",
    "#     male_counting = male_counting.drop(columns=[\"Min_TE_length\", \"Max_TE_length\", \"nb_of_insertion\"])\n",
    "#     TE_data_table = hierarchy.merge(female_counting, on='Family').merge(male_counting, on='Family')\n",
    "#     TE_data_table.columns = [\"Subclass\", \"Superfamily\", \"Family\", \"Min_TE_length\", \"Max_TE_length\", \"Female_Counts\", \"Nb_of_insertion\", \"Female_nb_of_expressed_insertion\", \"Female_most_expressed_insertion\", \"Male_Counts\", \"Male_nb_of_expressed_insertion\", \"Male_most_expressed_insertion\"]\n",
    "#     TE_data_table = TE_data_table[[\"Subclass\", \"Superfamily\", \"Family\", \"Nb_of_insertion\", \"Min_TE_length\", \"Max_TE_length\", \"Female_Counts\", \"Female_nb_of_expressed_insertion\", \"Female_most_expressed_insertion\", \"Male_Counts\", \"Male_nb_of_expressed_insertion\", \"Male_most_expressed_insertion\"]]\n",
    "#     return TE_data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subclass</th>\n",
       "      <th>Superfamily</th>\n",
       "      <th>Family</th>\n",
       "      <th>nb_of_insertion</th>\n",
       "      <th>Min_TE_length</th>\n",
       "      <th>Max_TE_length</th>\n",
       "      <th>Female_Counts</th>\n",
       "      <th>Female_nb_of_expressed_insertion</th>\n",
       "      <th>Female_most_expressed_insertion</th>\n",
       "      <th>Male_Counts</th>\n",
       "      <th>Male_nb_of_expressed_insertion</th>\n",
       "      <th>Male_most_expressed_insertion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINE</td>\n",
       "      <td>I</td>\n",
       "      <td>IVK_DM</td>\n",
       "      <td>39</td>\n",
       "      <td>196</td>\n",
       "      <td>7386</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>IVK_DM$3L_RaGOO$19656431$19661800</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>IVK_DM$3L_RaGOO$19656431$19661800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Gypsy</td>\n",
       "      <td>DM297_I</td>\n",
       "      <td>63</td>\n",
       "      <td>171</td>\n",
       "      <td>10825</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>DM297_I$2R_RaGOO$2216579$2220068</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>DM297_I$2R_RaGOO$16168$20202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LINE</td>\n",
       "      <td>I-Jockey</td>\n",
       "      <td>TAHRE</td>\n",
       "      <td>20</td>\n",
       "      <td>164</td>\n",
       "      <td>17305</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>TAHRE$2R_RaGOO$3700966$3703361</td>\n",
       "      <td>590</td>\n",
       "      <td>12</td>\n",
       "      <td>TAHRE$2R_RaGOO$1145909$1151824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LINE</td>\n",
       "      <td>I-Jockey</td>\n",
       "      <td>TART-A</td>\n",
       "      <td>13</td>\n",
       "      <td>169</td>\n",
       "      <td>8596</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>TART-A$3L_RaGOO$24811306$24813320</td>\n",
       "      <td>196</td>\n",
       "      <td>9</td>\n",
       "      <td>TART-A$X_RaGOO$3$3271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Gypsy</td>\n",
       "      <td>MDG1_LTR</td>\n",
       "      <td>27</td>\n",
       "      <td>170</td>\n",
       "      <td>7346</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>MDG1_LTR$2L_RaGOO$1126248$1133534</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>MDG1_LTR$3L_RaGOO$22730419$22737426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Gypsy</td>\n",
       "      <td>Chimpo_I</td>\n",
       "      <td>5</td>\n",
       "      <td>1166</td>\n",
       "      <td>4154</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chimpo_I$4_RaGOO$776018$780171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chimpo_I$3L_RaGOO$24683105$24684455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>FUSHI_DM</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FUSHI_DM$3R_RaGOO$6278611$6278764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FUSHI_DM$3R_RaGOO$6278611$6278764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>LTR</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>ARS406_DM</td>\n",
       "      <td>4</td>\n",
       "      <td>194</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ARS406_DM$X_RaGOO$9619999$9620210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ARS406_DM$X_RaGOO$9619999$9620210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>DNA</td>\n",
       "      <td>RC</td>\n",
       "      <td>Helitron1_DM</td>\n",
       "      <td>1</td>\n",
       "      <td>564</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Helitron1_DM$X_RaGOO$21992722$21993285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Helitron1_DM$X_RaGOO$21992722$21993285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>LINE</td>\n",
       "      <td>R2</td>\n",
       "      <td>R2_DM</td>\n",
       "      <td>3</td>\n",
       "      <td>268</td>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R2_DM$X_RaGOO$21996205$21996472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>R2_DM$X_RaGOO$21996205$21996472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subclass Superfamily        Family  nb_of_insertion  Min_TE_length  \\\n",
       "0       LINE           I        IVK_DM               39            196   \n",
       "1        LTR       Gypsy       DM297_I               63            171   \n",
       "2       LINE    I-Jockey         TAHRE               20            164   \n",
       "3       LINE    I-Jockey        TART-A               13            169   \n",
       "4        LTR       Gypsy      MDG1_LTR               27            170   \n",
       "..       ...         ...           ...              ...            ...   \n",
       "192      LTR       Gypsy      Chimpo_I                5           1166   \n",
       "193      LTR     Unknown      FUSHI_DM                1            154   \n",
       "194      LTR     Unknown     ARS406_DM                4            194   \n",
       "195      DNA          RC  Helitron1_DM                1            564   \n",
       "196     LINE          R2         R2_DM                3            268   \n",
       "\n",
       "     Max_TE_length  Female_Counts  Female_nb_of_expressed_insertion  \\\n",
       "0             7386              3                                 2   \n",
       "1            10825              5                                 4   \n",
       "2            17305              8                                 5   \n",
       "3             8596              9                                 3   \n",
       "4             7346              4                                 4   \n",
       "..             ...            ...                               ...   \n",
       "192           4154              1                                 1   \n",
       "193            154              0                                 0   \n",
       "194            256              0                                 0   \n",
       "195            564              0                                 0   \n",
       "196            567              0                                 0   \n",
       "\n",
       "            Female_most_expressed_insertion  Male_Counts  \\\n",
       "0         IVK_DM$3L_RaGOO$19656431$19661800            3   \n",
       "1          DM297_I$2R_RaGOO$2216579$2220068            4   \n",
       "2            TAHRE$2R_RaGOO$3700966$3703361          590   \n",
       "3         TART-A$3L_RaGOO$24811306$24813320          196   \n",
       "4         MDG1_LTR$2L_RaGOO$1126248$1133534            5   \n",
       "..                                      ...          ...   \n",
       "192          Chimpo_I$4_RaGOO$776018$780171            0   \n",
       "193       FUSHI_DM$3R_RaGOO$6278611$6278764            0   \n",
       "194       ARS406_DM$X_RaGOO$9619999$9620210            0   \n",
       "195  Helitron1_DM$X_RaGOO$21992722$21993285            0   \n",
       "196         R2_DM$X_RaGOO$21996205$21996472            0   \n",
       "\n",
       "     Male_nb_of_expressed_insertion           Male_most_expressed_insertion  \n",
       "0                                 2       IVK_DM$3L_RaGOO$19656431$19661800  \n",
       "1                                 3            DM297_I$2R_RaGOO$16168$20202  \n",
       "2                                12          TAHRE$2R_RaGOO$1145909$1151824  \n",
       "3                                 9                   TART-A$X_RaGOO$3$3271  \n",
       "4                                 3     MDG1_LTR$3L_RaGOO$22730419$22737426  \n",
       "..                              ...                                     ...  \n",
       "192                               0     Chimpo_I$3L_RaGOO$24683105$24684455  \n",
       "193                               0       FUSHI_DM$3R_RaGOO$6278611$6278764  \n",
       "194                               0       ARS406_DM$X_RaGOO$9619999$9620210  \n",
       "195                               0  Helitron1_DM$X_RaGOO$21992722$21993285  \n",
       "196                               0         R2_DM$X_RaGOO$21996205$21996472  \n",
       "\n",
       "[197 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_full_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_counting_to_df(counting_dict):\n",
    "    family_list = []\n",
    "    min_TE_length_list = []\n",
    "    max_TE_length_list = []\n",
    "    counting_list = []\n",
    "    nb_expressed_insertion_list = []\n",
    "    nb_insertion_list = []\n",
    "    most_expressed_insertion_list = []\n",
    "    for family, insertion_list in counting_dict.items():\n",
    "        family_list.append(family)\n",
    "        nb_insertion_list.append(len(insertion_list))\n",
    "        nb_expressed_insertion = 0\n",
    "        min_TE_length = 9999999999\n",
    "        max_TE_length = 0\n",
    "        family_counts = 0\n",
    "        most_expressed_insertion = None\n",
    "        max_count = 0\n",
    "        for insertion in insertion_list :\n",
    "            insertion_length = insertion.end - insertion.start\n",
    "            min_TE_length = min(min_TE_length, insertion_length)\n",
    "            max_TE_length = max(max_TE_length, insertion_length)\n",
    "            family_counts += insertion.counts\n",
    "            max_count = max(max_count,insertion.counts)\n",
    "            if insertion.counts >= max_count :\n",
    "                most_expressed_insertion = insertion.id\n",
    "            if insertion.counts > 0 :\n",
    "                nb_expressed_insertion += 1\n",
    "        nb_expressed_insertion_list.append(nb_expressed_insertion)\n",
    "        min_TE_length_list.append(min_TE_length)\n",
    "        max_TE_length_list.append(max_TE_length)\n",
    "        counting_list.append(family_counts)\n",
    "        most_expressed_insertion_list.append(most_expressed_insertion)\n",
    "        \n",
    "    counting_df = pd.DataFrame(list(zip(family_list, min_TE_length_list, max_TE_length_list, counting_list, nb_insertion_list, nb_expressed_insertion_list, most_expressed_insertion_list)), columns=[\"Family\", \"Min_TE_length\",\"Max_TE_length\", \"Counts\", \"nb_of_insertion\", \"nb_of_expressed_insertion\", \"Most_expressed_insertion\"])\n",
    "    return counting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export reads mapped on the 3 expressed insertions of POGO.\n",
    "\n",
    "#### Get ID of reads mapped on POGO\n",
    "\n",
    "# insertion = \"POGO_3L_RaGOO_9733928_9735150\"\n",
    "# insertion = \"POGO_X_RaGOO_21863530_21864880\"\n",
    "# insertion = \"POGO_2R_RaGOO_7201268_7202754\"\n",
    "\n",
    "# mapped_reads = saved_FC30_counting_df[saved_FC30_counting_df[\"Insertion\"] == insertion][\"Reads\"]\n",
    "# mapped_reads = mapped_reads.iloc[0].split(\"'\")\n",
    "# reads_IDs = []\n",
    "# for i, j in enumerate(mapped_reads):\n",
    "# \tif i % 2 :\n",
    "# \t\treads_IDs.append(j)\n",
    "# test =  pysam.AlignmentFile(FC30_DMGOTH_MAX_AS_BAMFILE, \"r\")\n",
    "# read_it = test.fetch(contig = \"2R_RaGOO\", start = 7201268, end = 7202754)\n",
    "# with open(insertion + \".mapped_read.fasta\", 'w') as output:\n",
    "# \tfor read in read_it:\n",
    "# \t\tif read.query_name in reads_IDs:\n",
    "# \t\t\tif read.query_sequence != None:\n",
    "# \t\t\t\tnew_line = \"> \" + read.query_name + \"\\n\" + read.query_sequence + \"\\n\"\n",
    "# \t\t\t\toutput.write(new_line)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
